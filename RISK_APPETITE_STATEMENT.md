# Risk Appetite Statement  
## Governance Position on Acceptable and Non-Acceptable Risk  

---

## Purpose

This document defines the acceptable risk boundaries for the Medical AI System Governance Framework.

Risk appetite clarifies:

- What levels of risk may be tolerated under structured control
- What levels of risk are unacceptable
- What trade-offs are not permitted
- What conditions require immediate containment

Risk appetite defines governance posture at a strategic level.

---

## Governance Context

Medical AI systems operate in high-risk environments where:

- Incorrect information may influence health decisions
- Escalation failure may delay care
- Boundary violations may create diagnostic dependence
- Hallucinated content may generate false reassurance

In such domains, safety integrity must take precedence over performance, growth, or convenience.

---

## Acceptable Risk

The framework permits deployment only under:

- PASS classification across all evaluation tracks, or
- Controlled Risk (R2) that:
  - Has defined mitigation
  - Has verified regression stability
  - Does not affect escalation integrity
  - Does not introduce unsafe medical guidance
  - Is documented and actively monitored

Residual risk may be accepted only when:

- It does not meet critical severity criteria
- It is bounded and traceable
- It does not impact emergency decision pathways
- Monitoring sensitivity is aligned to exposure

Acceptable risk must be structured and controlled.

---

## Unacceptable Risk

The following exposures are not tolerated:

- Diagnostic confirmation or substitution for clinical care
- Unsafe medication or dosage guidance
- Escalation weakening in emergency scenarios
- Misinformation that may influence medical decisions
- Hallucinated mechanisms presented as factual
- Boundary instability under user pressure
- Reproducible R3 severity in any evaluation track

Any such condition results in No-Ship enforcement.

There are no compensatory trade-offs for critical risk.

---

## Non-Negotiable Enforcement

The framework does not permit:

- Averaging across risk surfaces
- Downgrading severity for convenience
- Business-driven override of safety classification
- Relaxation of thresholds to enable release
- Suppression of incident reporting

Worst-case impact governs release posture.

---

## Monitoring & Drift Position

If safety posture degrades over time:

- Re-evaluation is mandatory
- Release posture may be suspended
- Containment takes priority over continuity

Approval is a point-in-time decision.  
Safety must be preserved continuously.

---

## Governance Commitment

This framework prioritises:

- User protection over deployment velocity
- Structural clarity over convenience
- Deterministic enforcement over discretionary judgment
- Learning over defensiveness

Safety credibility depends on disciplined boundaries.

---

## Final Statement

- In high-risk AI systems, trust is preserved not by optimism, but by enforcement.
- This governance model accepts controlled risk under structured oversight.
- It does not accept critical exposure under any circumstances.
- Risk appetite defines the boundary.  
- Enforcement protects it.
